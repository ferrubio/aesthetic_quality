{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set up Python environment: numpy for numerical routines\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# for store the results\n",
    "from six.moves import cPickle as pickle\n",
    "import gzip\n",
    "\n",
    "# our code (utilsData needs a view)\n",
    "import sys\n",
    "sys.path.append('../pycode/')\n",
    "import utilsData\n",
    "from preprocess import utilities\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# own models and functions\n",
    "from preprocess.mdl import MDL_method\n",
    "from preprocess.unsupervised import Unsupervised_method\n",
    "from models.nb import Naive_Bayes\n",
    "from models.aode_fast import AODE_fast\n",
    "\n",
    "# default models from scikit\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os, os.path\n",
    "\n",
    "mainPath='/home/frubio/AVA/'\n",
    "featuresPath = \"/home/frubio/aesthetic_quality/features/dSIFT/initialRad{:d}_scales{:d}_factor{:.1f}/AVA/\"\n",
    "\n",
    "import fisher_vector\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load and Train NB with Histogram of Gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "features_file = '../features/AVA/GHIST.arff'\n",
    "#features_file = '../features/features_pool5_ResNet.pklz'\n",
    "output_file = '../prueba.pklz'\n",
    "selected_model = 'NBG'\n",
    "decaf_discrete = 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frubio/aestheticVenv/lib/python3.4/site-packages/ipykernel/__main__.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "if features_file[-4:] == 'pklz':\n",
    "    features = pickle.load(open(features_file,'rb',2))\n",
    "else:\n",
    "    features = utilsData.readARFF(features_file)\n",
    "    \n",
    "features['id'] = features['id'].astype(int)\n",
    "#for test in notebooks\n",
    "#features = features.iloc[:,-101:]\n",
    "\n",
    "# we take the name of the features and delete de ID\n",
    "features_names = np.array(features.columns)\n",
    "index = np.argwhere(features_names=='id')\n",
    "features_names = np.delete(features_names, index)\n",
    "\n",
    "# this line is for normalize decaf features\n",
    "if (decaf_discrete == 'True'):\n",
    "    features[features_names],_ = utilities.reference_forward_implementation(np.array(features[features_names]),5,2,1.5,0.75)\n",
    "\n",
    "data = pickle.load(gzip.open('../packages/AVA_info.pklz','rb',2))\n",
    "data = data.merge(features, on='id', copy=False)\n",
    "\n",
    "num_images = data.shape[0]\n",
    "\n",
    "data_aux = data[np.append(features_names,['Class'])]\n",
    "data_aux['Class'] = pd.Categorical(data_aux['Class'],range(0,len(data_aux['Class'].unique())))\n",
    "\n",
    "# to free space\n",
    "del features\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fold = data_aux.copy()\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(data_fold.loc[:,features_names],data_fold['Class'].cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Testing speed of histogram extraction and NB classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## all process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 5.77 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "img = cv2.imread('../fondo1.jpg',0)\n",
    "hist = np.histogram(img, bins = 256, range=(0,256), density = True)[0]\n",
    "#hist = pd.DataFrame(data=[hist],columns=data_aux.columns[0:-1])\n",
    "\n",
    "#hist = discretization.process(hist)\n",
    "results = model.predict_proba(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Now is the turn for the SIFT and FV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extractSizeFromRadius(radius):\n",
    "    SIFT_DESCR_WIDTH = 4\n",
    "    SIFT_DESCR_SCL_FCTR = 3.0\n",
    "\n",
    "    final_size = radius / (SIFT_DESCR_SCL_FCTR * (SIFT_DESCR_WIDTH + 1) * 0.5 * 0.5 * 1.4142135623730951)\n",
    "    return final_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class FV_dictionary:\n",
    "    \n",
    "    def __init__(self,size_PCA, size_patch, size_gmm):\n",
    "        self.size_patch = size_patch\n",
    "        self.pca = PCA(n_components=size_PCA)\n",
    "        self.gmm = GaussianMixture(n_components=size_gmm, covariance_type='diag')\n",
    "        self.size_descriptor = 0\n",
    "        \n",
    "    def generate_dict(self,indexes,files,path):\n",
    "        \n",
    "        matrix_features = self.extract_patch_features(indexes, files, path)\n",
    "        \n",
    "        descriptor_size = matrix_features.shape[1]\n",
    "        if descriptor_size > self.pca.n_components:\n",
    "            self.pca.fit(matrix_features)\n",
    "            matrix_features = self.pca.transform(matrix_features)\n",
    "            self.size_descriptor = self.pca.n_components\n",
    "        else:\n",
    "            self.size_descriptor = descriptor_size\n",
    "            \n",
    "        self.gmm.fit(matrix_features)\n",
    "        \n",
    "    def obtain_fv(self,indexes,files,path):\n",
    "        \n",
    "        fv_size = self.gmm.n_components*(1+2*self.size_descriptor)\n",
    "        final_matrix = np.zeros((indexes.shape[0],fv_size))\n",
    "        counter = 0\n",
    "        for i in indexes:\n",
    "            fname=path+files[i]+'.pklz'\n",
    "            if os.path.isfile(fname):\n",
    "                sift = pickle.load(gzip.open(fname,\"rb\",2))\n",
    "                descriptor_size = sift.shape[1]\n",
    "                if descriptor_size > self.pca.n_components:\n",
    "                    sift = self.pca.transform(sift)\n",
    "                final_matrix[counter] = fisher_vector.fisher_vector(sift, self.gmm)\n",
    "                counter += 1\n",
    "        return final_matrix\n",
    "    \n",
    "    def extract_patch_features(self, indexes, files, path):\n",
    "        # We extract the number of vectors corresponding to the size of the patch / number of images\n",
    "        nImages = indexes.shape[0]\n",
    "        featuresPerImage = int(self.size_patch / nImages)\n",
    "        finalMatrix = np.zeros((featuresPerImage*nImages, 128),dtype=np.float32)\n",
    "\n",
    "        counter = 0\n",
    "        \n",
    "        for i in indexes:\n",
    "            fname=path+files[i]+'.pklz'\n",
    "            if os.path.isfile(fname):\n",
    "                sift = pickle.load(gzip.open(fname,\"rb\",2))\n",
    "                selectedFeat = np.random.choice(range(0,sift.shape[0]),replace=False,size=featuresPerImage)\n",
    "                finalMatrix[counter:counter+featuresPerImage] = sift[selectedFeat]\n",
    "            counter += featuresPerImage\n",
    "        return finalMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Parameters of the classification\n",
    "delta = 0\n",
    "\n",
    "# Parameters of the descriptors\n",
    "scales = 5\n",
    "initial_radius = 16\n",
    "factor_step = 1.2\n",
    "\n",
    "# Parameters for the FV\n",
    "size_patch = 1000\n",
    "size_PCA = 64\n",
    "size_gmm = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = pickle.load(gzip.open('../packages/AVA_info.pklz','rb',2))\n",
    "num_images = len(data)\n",
    "data.loc[:,'id'] = data['id'].apply(str)\n",
    "classes = np.array(data.sort_values(['id']).loc[:,'Class'])\n",
    "means = np.array(data.sort_values(['id']).loc[:,'VotesMean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dictionary = FV_dictionary(size_PCA,size_patch,size_gmm)\n",
    "dictionary.generate_dict(np.array(range(0,100)),np.array(data.sort_values(['id'])['id']),featuresPath.format(initial_radius,scales,factor_step))\n",
    "train_features = dictionary.obtain_fv(np.array(range(0,100)),np.array(data.sort_values(['id'])['id']),featuresPath.format(initial_radius,scales,factor_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "sgd_clf.fit(train_features, classes[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 129 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "img = cv2.imread('../fondo1.jpg',0)\n",
    "radius = initial_radius\n",
    "for i in range(0,scales):\n",
    "    step_size = extractSizeFromRadius(radius)\n",
    "    kp = [cv2.KeyPoint(x, y, step_size) for y in range(radius, img.shape[0], radius*2) \n",
    "                                    for x in range(radius, img.shape[1], radius*2)]\n",
    "    dense_feat = sift.compute(img, kp)\n",
    "\n",
    "    if i==0:\n",
    "        final_feat = dense_feat[1]\n",
    "    else:\n",
    "        final_feat = np.concatenate((final_feat,dense_feat[1]), axis=0)\n",
    "\n",
    "    radius = int(np.around(radius*factor_step))\n",
    "    \n",
    "final_feat = dictionary.pca.transform(final_feat)\n",
    "final_vector = fisher_vector.fisher_vector(final_feat, dictionary.gmm)\n",
    "predictions = sgd_clf.predict(final_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
