{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Classifiers based on features extracted from matlab\n",
    "\n",
    "In this notebook we use the different arff files obtained from matlab. We will use this features to obtain classifiers and test them in a cross validation process.\n",
    "\n",
    "## A bit of set up\n",
    "\n",
    "We need numpy and pandas for data. Pickle and gzip for read the extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set up Python environment: numpy for numerical routines\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# for store the results\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "import sys\n",
    "sys.path.append('../pycode/')\n",
    "import utilsData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this example we only use the default linear SVM classifier from libsvm and the Gaussian NB from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Feature reading\n",
    "\n",
    "In this example only one package is read, but each ones have a size of 80Mb approximately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'packages/info.pklz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2753196184ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'packages/info.pklz'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.4/gzip.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"write\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'packages/info.pklz'"
     ]
    }
   ],
   "source": [
    "data = pickle.load(gzip.open('../packages/AVA_info.pklz','rb',2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-10d5dc7e94ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m             '11_bins50_levels2_angle360.arff', '12_bins20_levels2_angle360.arff']\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# this is for use the same random than in DeCAF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "total_files=['PHOG/','CHIST.arff', 'GHIST.arff', 'GIST_ori8_block4.arff', 'Centrist.arff']\n",
    "phog_files=['2_bins360_levels0_angle360.arff', '3_bins300_levels0_angle360.arff', '4_bins200_levels0_angle360.arff',\n",
    "            '5_bins100_levels0_angle360.arff', '6_bins50_levels0_angle360.arff', '7_bins20_levels0_angle360.arff',\n",
    "            '8_bins100_levels1_angle360.arff', '9_bins50_levels1_angle360.arff', '10_bins20_levels1_angle360_redux.arff',\n",
    "            '11_bins50_levels2_angle360.arff', '12_bins20_levels2_angle360.arff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utilsData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6afcb0c50c9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutilsData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadARFF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'features/AVA/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtotal_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mphog_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutilsData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadARFF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'features/AVA/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtotal_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'utilsData' is not defined"
     ]
    }
   ],
   "source": [
    "if sys.argv[1] == '0':\n",
    "    features = utilsData.readARFF('features/AVA/'+total_files[int(sys.argv[1])]+phog_files[int(sys.argv[2])])\n",
    "else:\n",
    "    features = utilsData.readARFF('features/AVA/'+total_files[int(sys.argv[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This block must be eliminated, is only for test in the notebook\n",
    "batches = 100\n",
    "delta = 2.5\n",
    "sys.path.append('../pycode/')\n",
    "import utilsData\n",
    "features = utilsData.readARFF('../features/AVA/PHOG/2_bins360_levels0_angle360.arff')\n",
    "data = pickle.load(gzip.open('../packages/AVA_info.pklz','rb',2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "features=pd.DataFrame(features['data'],columns=features['vars'])\n",
    "features=features.rename(columns=(lambda x: 'var'+str(int(x[3:])-1)))\n",
    "features=features.rename(columns={'var0':'id'})\n",
    "\n",
    "num_features = len(features.columns)-1\n",
    "data=pd.merge(data, features, on='id', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_images = len(data)\n",
    "\n",
    "votesList=np.array(data.iloc[:,2:12])\n",
    "auxTotal=np.sum(votesList,axis=1)\n",
    "auxMeanVector=np.sum(votesList*range(1,11),axis=1)/auxTotal.astype(np.float)\n",
    "auxClass=np.array(auxMeanVector >= 5, dtype=np.int)\n",
    "\n",
    "data.loc[:,'VotesMean'] = pd.Series(auxMeanVector, index=data.index)\n",
    "data.loc[:,'Class'] = pd.Series(auxClass, index=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data.loc[:,'id'] = data['id'].apply(str)\n",
    "classes = np.array(data.sort_values(['id']).loc[:,'Class'])\n",
    "features = np.array(data.sort_values(['id']).iloc[:,37:num_features+37])\n",
    "means = np.array(data.sort_values(['id']).loc[:,'VotesMean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "indexes = np.array(range(0,len(classes))[:len(classes)-(len(classes) % batches)])\n",
    "indexes = indexes.reshape((batches,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Cross validation\n",
    "\n",
    "In this case, we prepare vectors with the batches of each fold in order to test them in galgo and store the results.\n",
    "\n",
    "* First, we split the batches in 5 folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1000)\n",
    "num_folds = 5\n",
    "batches = 100\n",
    "delta = 2\n",
    "folds = np.random.choice(range(0,batches),replace=False,size=(num_folds,int(batches/num_folds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def balance_class(features, classes):\n",
    "    classes_uniques = np.unique(classes)\n",
    "    min_class = np.array([0,float('Inf')])\n",
    "    for i in classes_uniques:\n",
    "        aux_value = np.sum(classes == i)\n",
    "        if aux_value < min_class[1]:\n",
    "            min_class = np.array([i,aux_value])\n",
    "            \n",
    "    final_indexes = np.where(classes == min_class[0])[0]\n",
    "    for i in classes_uniques:\n",
    "        if i != min_class[0]:\n",
    "            aux_indexes = np.where(classes == i)[0]\n",
    "            #print np.random.choice(aux_indexes,replace=False,size=min_class[1])\n",
    "            final_indexes = np.concatenate((final_indexes,np.random.choice(aux_indexes,replace=False,size=min_class[1])))\n",
    "            \n",
    "    final_indexes = np.sort(final_indexes)\n",
    "    return (features[final_indexes],classes[final_indexes])\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0      1      2 ..., 110899 110900 110904]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'svm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-6e6f2a24808e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Fit models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0msvm_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0msvm_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'svm' is not defined"
     ]
    }
   ],
   "source": [
    "sum_folds_svm = 0\n",
    "sum_folds_nbg = 0\n",
    "matrix_svm = np.zeros((2,2))\n",
    "matrix_nbg = np.zeros((2,2))\n",
    "for i in range(0, num_folds):\n",
    "    \n",
    "    # Prepare train\n",
    "    train_indices = indexes[np.delete(folds,i,axis=0).reshape(-1)].reshape(-1)\n",
    "    train_features = features[train_indices]\n",
    "    train_classes = classes[train_indices]\n",
    "    train_means = means[train_indices]\n",
    "    \n",
    "    # Delete values depending on the delta\n",
    "    vector_out_delta = (train_means <= 5-delta) | (train_means >= 5+delta)\n",
    "    train_features = train_features[vector_out_delta]\n",
    "    train_classes = train_classes[vector_out_delta]\n",
    "    \n",
    "    # Class balance\n",
    "    train_features,train_classes = balance_class(train_features,train_classes)\n",
    "    \n",
    "    # Fit models\n",
    "    svm_clf = svm.LinearSVC()\n",
    "    svm_clf.fit(train_features, train_classes)\n",
    "\n",
    "    nbg_clf = GaussianNB()\n",
    "    nbg_clf.fit(train_features, train_classes)\n",
    "    \n",
    "    # Prepare test\n",
    "    test_indices = indexes[folds[i]].reshape(-1)\n",
    "    test_features = features[test_indices]\n",
    "    test_classes = classes[test_indices]\n",
    "    \n",
    "    # Evaluate SVM model\n",
    "    predictions = svm_clf.predict(test_features)\n",
    "    results = np.sum(predictions == test_classes)/float(len(predictions))\n",
    "    sum_folds_svm += results\n",
    "    \n",
    "    matrix_svm[0,0] += np.sum(predictions[predictions == test_classes] == 0)\n",
    "    matrix_svm[0,1] += np.sum(predictions[predictions != test_classes] == 1)\n",
    "    matrix_svm[1,0] += np.sum(predictions[predictions != test_classes] == 0)\n",
    "    matrix_svm[1,1] += np.sum(predictions[predictions == test_classes] == 1)\n",
    "    \n",
    "    # Evaluate gnb model\n",
    "    predictions = nbg_clf.predict(test_features)\n",
    "    results = np.sum(predictions == test_classes)/float(len(predictions))\n",
    "    sum_folds_nbg += results\n",
    "    \n",
    "    matrix_nbg[0,0] += np.sum(predictions[predictions == test_classes] == 0)\n",
    "    matrix_nbg[0,1] += np.sum(predictions[predictions != test_classes] == 1)\n",
    "    matrix_nbg[1,0] += np.sum(predictions[predictions != test_classes] == 0)\n",
    "    matrix_nbg[1,1] += np.sum(predictions[predictions == test_classes] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-0b56ea85b91b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msum_folds_svm\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnum_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'conf_matrix'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmatrix_svm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'classifier'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'SVM-L'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'descriptor'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtotal_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'delta'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdata_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'case'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mphog_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"results/SVM_balanced_Descriptor%d_Case%d.pklz\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'total_files' is not defined"
     ]
    }
   ],
   "source": [
    "data_results = {'accuracy':sum_folds_svm/num_folds, 'conf_matrix':matrix_svm, 'classifier':'SVM-L', 'descriptor':total_files[int(sys.argv[1])], 'delta':delta}\n",
    "if sys.argv[1] == '0':\n",
    "    data_results['case']=phog_files[int(sys.argv[2])]\n",
    "    pickle.dump(data_results, gzip.open(\"results/SVM_balanced_Descriptor%d_Case%d.pklz\" % (int(sys.argv[1]),int(sys.argv[2])), \"wb\" ), 2)\n",
    "else:\n",
    "    pickle.dump(data_results, gzip.open(\"results/SVM_balanced_Descriptor%d.pklz\" % (int(sys.argv[1])), \"wb\" ), 2)\n",
    "\n",
    "data_results = {'accuracy':sum_folds_nbg/num_folds, 'conf_matrix':matrix_nbg, 'classifier':'NB-G', 'descriptor':total_files[int(sys.argv[1])], 'delta':delta}\n",
    "if sys.argv[1] == '0':\n",
    "    data_results['case']=phog_files[int(sys.argv[2])]\n",
    "    pickle.dump(data_results, gzip.open(\"results/GNB_balanced_Descriptor%d_Case%d.pklz\" % (int(sys.argv[1]),int(sys.argv[2])), \"wb\" ), 2)\n",
    "else:\n",
    "    pickle.dump(data_results, gzip.open(\"results/GNB_balanced_Descriptor%d.pklz\" % (int(sys.argv[1])), \"wb\" ), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0x83 in position 5: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-ef8b87fc9cd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdict_rest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../results/GNB_balanced_Descriptor0_Case0.pklz'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0x83 in position 5: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "dict_rest = pickle.load(gzip.open('../results/GNB_balanced_Descriptor0_Case0.pklz','rb',2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
