{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Classification: Instant Recognition with Caffe\n",
    "\n",
    "In this example we'll classify an image with the bundled CaffeNet model (which is based on the network architecture of Krizhevsky et al. for ImageNet).\n",
    "\n",
    "We'll compare CPU and GPU modes and then dig into the model to inspect features and the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. Setup\n",
    "\n",
    "* First, set up Python, `numpy`, and `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set up Python environment: numpy for numerical routines, and matplotlib for plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for store the results\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "# display plots in this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# set display defaults\n",
    "plt.rcParams['figure.figsize'] = (10, 5)        # large images\n",
    "plt.rcParams['image.interpolation'] = 'nearest'  # don't interpolate: show square pixels\n",
    "plt.rcParams['image.cmap'] = 'gray'  # use grayscale output rather than a (potentially misleading) color heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* Load `caffe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The caffe module needs to be on the Python path;\n",
    "#  we'll add it here explicitly.\n",
    "import sys\n",
    "import os\n",
    "caffe_root = '/opt/caffe/'  # this file should be run from {caffe_root}/examples (otherwise change this line)\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "\n",
    "import caffe\n",
    "# If you get \"No module named _caffe\", either you have not built pycaffe or you have the wrong path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Load net and set up input preprocessing\n",
    "\n",
    "* Set Caffe to GPU mode (Tesla) and load the net from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "caffe.set_device(0)  # if we have multiple GPUs, pick the first one\n",
    "#caffe.set_mode_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_def = caffe_root + 'models/bvlc_reference_caffenet/deploy.prototxt'\n",
    "model_weights = caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'\n",
    "\n",
    "net = caffe.Net(model_def,      # defines the structure of the model\n",
    "                model_weights,  # contains the trained weights\n",
    "                caffe.TEST)     # use test mode (e.g., don't perform dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* Set up input preprocessing. (We'll use Caffe's `caffe.io.Transformer` to do this, but this step is independent of other parts of Caffe, so any custom preprocessing code may be used).\n",
    "\n",
    "    Our default CaffeNet is configured to take images in BGR format. Values are expected to start in the range [0, 255] and then have the mean ImageNet pixel value subtracted from them. In addition, the channel dimension is expected as the first (_outermost_) dimension.\n",
    "    \n",
    "    As matplotlib will load images with values in the range [0, 1] in RGB format with the channel as the _innermost_ dimension, we are arranging for the needed transformations here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load the mean ImageNet image (as distributed with Caffe) for subtraction\n",
    "mu = np.load(caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy')\n",
    "mu = mu.mean(1).mean(1)  # average over pixels to obtain the mean (BGR) pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create transformer for the input called 'data'\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "transformer.set_transpose('data', (2,0,1))  # move image channels to outermost dimension\n",
    "transformer.set_mean('data', mu)            # subtract the dataset-mean value in each channel\n",
    "transformer.set_raw_scale('data', 255)      # rescale from [0, 1] to [0, 255]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # swap channels from RGB to BGR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3. Extract the features\n",
    "\n",
    "* Now we're ready to perform classification. First we create an array with the files of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "images_root = '/home/frubio/ViDriLo/%s/visualInformation/'\n",
    "folders = ['Sequence1','Sequence2','Sequence3','Sequence4','Sequence5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* This function extracts decaf features in batches of a list of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extract_decaf_features(images_root,list_images,layer,net,transformer):\n",
    "    # set the size of the input (we can skip this if we're happy\n",
    "    # with the default; we can also change it later, e.g., for different batch sizes)\n",
    "    batch, C, H, W = net.blobs['data'].shape\n",
    "    \n",
    "    num_images = len(list_images)\n",
    "    \n",
    "    output_shape = net.blobs[layer].shape\n",
    "    output_shape[0] = num_images\n",
    "    output = np.zeros(output_shape)\n",
    "    \n",
    "    count = 0\n",
    "    while count < num_images:\n",
    "        pre_count = count    \n",
    "        for i in range(0,batch):\n",
    "            if count >= num_images:\n",
    "                i -= 1\n",
    "                break\n",
    "            try:\n",
    "                image = caffe.io.load_image(images_root + list_images[count])\n",
    "                if len(image.shape)>3:\n",
    "                    image = image[0]\n",
    "                transformed_image = transformer.preprocess('data', image)\n",
    "                net.blobs['data'].data[i] = transformed_image\n",
    "            except:\n",
    "                print (count)\n",
    "                raise\n",
    "            count += 1\n",
    "        \n",
    "        net.forward()\n",
    "    \n",
    "        output[pre_count:count]=net.blobs[layer].data[0:i+1]\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* Finally, we call the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for k in folders:\n",
    "\n",
    "    list_images = os.listdir(images_root % k)\n",
    "    list_images.sort()\n",
    "    \n",
    "    features_path = \"features/ViDriLo/%s/\" % k\n",
    "    \n",
    "    if not os.path.exists(features_path):\n",
    "        os.makedirs(features_path)\n",
    "        \n",
    "    if not os.path.exists(features_path+\"pool5_caffenet\"):\n",
    "        os.makedirs(features_path+\"pool5_caffenet\")\n",
    "    \n",
    "    if not os.path.exists(features_path+\"fc6_caffenet\"):\n",
    "        os.makedirs(features_path+\"fc6_caffenet\")\n",
    "    \n",
    "    if not os.path.exists(features_path+\"fc7_caffenet\"):\n",
    "        os.makedirs(features_path+\"fc7_caffenet\")    \n",
    "    \n",
    "    decaf_features = extract_decaf_features(images_root%k,list_images,'pool5',net,transformer)\n",
    "    pickle.dump(decaf_features, gzip.open( features_path+\"pool5_caffenet/pool5_caffenet.pklz\", \"wb\" ), 2)\n",
    "\n",
    "    decaf_features = extract_decaf_features(images_root%k,list_images,'fc6',net,transformer)\n",
    "    pickle.dump(decaf_features, gzip.open( features_path+\"fc6_caffenet/fc6_caffenet.pklz\", \"wb\" ), 2)\n",
    "\n",
    "    decaf_features = extract_decaf_features(images_root%k,list_images,'fc7',net,transformer)\n",
    "    pickle.dump(decaf_features, gzip.open( features_path+\"fc7_caffenet/fc7_caffenet.pklz\", \"wb\" ), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_def = caffe_root + 'models/ResNet-152/ResNet-152-deploy.prototxt'\n",
    "model_weights = caffe_root + 'models/ResNet-152/ResNet-152-model.caffemodel'\n",
    "\n",
    "net = caffe.Net(model_def,      # defines the structure of the model\n",
    "                model_weights,  # contains the trained weights\n",
    "                caffe.TEST)     # use test mode (e.g., don't perform dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "transformer.set_transpose('data', (2,0,1))  # move image channels to outermost dimension\n",
    "transformer.set_mean('data', mu)            # subtract the dataset-mean value in each channel\n",
    "transformer.set_raw_scale('data', 255)      # rescale from [0, 1] to [0, 255]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # swap channels from RGB to BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for k in folders:\n",
    "\n",
    "    list_images = os.listdir(images_root % k)\n",
    "    list_images.sort()\n",
    "    \n",
    "    features_path = \"features/KTH-IDOL/Minnie/%s/\" % k\n",
    "    \n",
    "    if not os.path.exists(features_path):\n",
    "        os.makedirs(features_path)\n",
    "\n",
    "    if not os.path.exists(features_path+\"pool5_ResNet-152\"):\n",
    "        os.makedirs(features_path+\"pool5_ResNet-152\")\n",
    "    \n",
    "    decaf_features = extract_decaf_features(images_root%k,list_images,'pool5',net,transformer)\n",
    "    pickle.dump(decaf_features, gzip.open( features_path+\"pool5_ResNet-152/pool5_ResNet-152.pklz\", \"wb\" ), 2)"
   ]
  }
 ],
 "metadata": {
  "description": "Instant recognition with a pre-trained model and a tour of the net interface for visualizing features and parameters layer-by-layer.",
  "example_name": "Image Classification and Filter Visualization",
  "include_in_docs": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  },
  "priority": 1
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
