{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Aesthetic Classification\n",
    "\n",
    "In this notebook we work with different functions to make a model and obtain results from image descriptors.\n",
    "This will be an example in order to create scripts that generate automaticatly the results for our paper.\n",
    "\n",
    "## A bit of set up\n",
    "\n",
    "We need numpy and pandas for data. Pickle and gzip for read the extracted features. Our folder with the code of our functions. Different models from scikit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set up Python environment: numpy for numerical routines\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# for store the results\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "# default models from scikit\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# our code (utilsData needs a view)\n",
    "import sys\n",
    "sys.path.append('../pycode/')\n",
    "import utilsData\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from preprocess.mdl import MDL_method\n",
    "from preprocess.unsupervised import Unsupervised_method\n",
    "from models.nb import Naive_Bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## AVA dataset\n",
    "We start with AVA data. First, a info package must be load. It contains information about votes, style features, labels and IDs. Then with the information of the arff file and readARFF function, we extract the features with their IDs. Finally, the information is combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = utilsData.readARFF('../features/AVA/PHOG/2_bins360_levels0_angle360.arff')\n",
    "output_file = '../results/prueba1.pklz'\n",
    "selected_model = 'NB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = pickle.load(gzip.open('../packages/AVA_info.pklz','rb',2))\n",
    "\n",
    "# we take the name of the features and delete de ID\n",
    "features_names = np.array(features.columns)\n",
    "index = np.argwhere(features_names=='id')\n",
    "features_names = np.delete(features_names, index)\n",
    "\n",
    "data=pd.merge(data, features, on='id', how='right')\n",
    "num_images = data.shape[0]\n",
    "\n",
    "# to free space\n",
    "del features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "data_aux = data[np.append(features_names,['Class'])]\n",
    "data_aux['Class'] = pd.Categorical(data_aux['Class'],data_aux['Class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1000)\n",
    "num_folds = 5\n",
    "folds = np.random.choice(range(0,num_images),replace=False,size=(num_folds,int(num_images/num_folds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy\n",
      "0.556664730141\n",
      "\n",
      "AUC\n",
      "0.605629277345\n",
      "\n",
      "Accuracy\n",
      "0.643183865283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "results['balanced']=0\n",
    "results['AUC']=0\n",
    "results['accuracy']=0\n",
    "\n",
    "for i in range(0, num_folds):\n",
    "    \n",
    "    train_indices = np.delete(folds,i,axis=0).reshape(-1)\n",
    "    train_indices = train_indices[utilsData.balance_class(data_aux['Class'].cat.codes[train_indices])]\n",
    "    \n",
    "    test_indices = folds[i]\n",
    "    \n",
    "    if selected_model == 'NB':\n",
    "    \n",
    "        discretization = MDL_method()\n",
    "        #discretization.frequency = True\n",
    "\n",
    "        discretization.train(data_aux.loc[train_indices])\n",
    "        data_fold = discretization.process(data_aux)\n",
    "    \n",
    "        model = Naive_Bayes()\n",
    "        model.fit(data_fold.loc[train_indices])\n",
    "    \n",
    "        predictions =  model.predict_proba(data_fold.loc[test_indices])[1]\n",
    "    \n",
    "    elif selected_model == 'NBG'\n",
    "        data_fold = data_aux.copy()\n",
    "    \n",
    "        model = GaussianNB()\n",
    "        model.fit(data_fold.loc[train_indices,features_names],data_fold['Class'].cat.codes[train_indices])\n",
    "        \n",
    "        predictions =  model.predict_proba(data_fold.loc[test_indices,features_names])[:,1]\n",
    "    \n",
    "    elif selected_model == 'SVM':\n",
    "        data_fold = data_aux.copy()\n",
    "    \n",
    "        model = LinearSVC()\n",
    "        model.fit(data_fold.loc[train_indices,features_names],data_fold['Class'].cat.codes[train_indices])\n",
    "        \n",
    "        predictions =  model.predict_proba(data_fold.loc[test_indices,features_names])[:,1]\n",
    "    \n",
    "    results['balanced'] += utilsData.balanced_accuracy(data_fold['Class'].cat.codes[test_indices], predictions)\n",
    "    results['AUC'] += roc_auc_score(data_fold['Class'].cat.codes[test_indices], predictions)\n",
    "    results['accuracy'] += accuracy_score(data_fold['Class'].cat.codes[test_indices], (predictions >= 0.5).astype(int))\n",
    "    \n",
    "results['balanced'] /= num_folds\n",
    "results['AUC'] /= num_folds\n",
    "results['accuracy'] /= num_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(results, gzip.open( output_file, \"wb\" ), 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
