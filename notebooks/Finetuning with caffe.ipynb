{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# set up Python environment: numpy for numerical routines, and matplotlib for plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# display plots in this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# for store the results\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "# for include pycode\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0,'../pycode')\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The caffe module needs to be on the Python path;\n",
    "#  we'll add it here explicitly.\n",
    "caffe_root = '/opt/caffe/'  # this file should be run from {caffe_root}/examples (otherwise change this line)\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "\n",
    "import caffe\n",
    "from caffe import layers as L\n",
    "# If you get \"No module named _caffe\", either you have not built pycaffe or you have the wrong path.\n",
    "\n",
    "\n",
    "import aestheticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generacion de train y test\n",
    "Primero creamos dos txt con la informacion del fichero y de su clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = pickle.load(gzip.open('../packages/info.pklz','rb',2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_images = len(data)\n",
    "\n",
    "votesList=np.array(data.iloc[:,2:12])\n",
    "auxTotal=np.sum(votesList,axis=1)\n",
    "auxMeanVector=np.sum(votesList*range(1,11),axis=1)/auxTotal.astype(np.float)\n",
    "auxClass=np.array(auxMeanVector >= 5, dtype=np.int)\n",
    "\n",
    "data.loc[:,'VotesMean'] = pd.Series(auxMeanVector, index=data.index)\n",
    "data.loc[:,'Class'] = pd.Series(auxClass, index=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.loc[:,'id'] = data['id'].apply(str)\n",
    "classes = np.array(data.sort_values(['id']).loc[:,'Class'])\n",
    "ids = np.array(data.sort_values(['id']).loc[:,'id'])\n",
    "aux_list =  np.array(['/home/frubio/AVA/AVADataset/{:}.jpg'.format(i) for i in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1000)\n",
    "random_idx = np.random.randint(2, size=len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_files = aux_list[random_idx == 0]\n",
    "train_classes = classes[random_idx == 0]\n",
    "test_files = aux_list[random_idx == 1]\n",
    "test_classes = classes[random_idx == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(list(zip(train_files,train_classes)))\n",
    "df_train.columns = ['image_filename', 'label']\n",
    "df_train.to_csv('../../AVA/train_partition_finetuning.txt', sep=' ', header=None, index=None)\n",
    "\n",
    "df_test = pd.DataFrame(list(zip(test_files,test_classes)))\n",
    "df_test.columns = ['image_filename', 'label']\n",
    "df_test.to_csv('../../AVA/test_partition_finetuning.txt', sep=' ', header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aqui comienza la chicha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "caffe.set_device(0)  # if we have multiple GPUs, pick the first one\n",
    "#caffe.set_mode_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weights = caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dummy_data = L.DummyData(shape=dict(dim=[1, 3, 227, 227]))\n",
    "imagenet_net_filename = aestheticNet.caffenet(data=dummy_data, train=False)\n",
    "imagenet_net = caffe.Net(imagenet_net_filename, weights, caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running solvers for 200 iterations...\n",
      "  0) pretrained: loss=0.693, acc=72%\n",
      " 10) pretrained: loss=0.785, acc=64%\n",
      " 20) pretrained: loss=0.889, acc=56%\n",
      " 30) pretrained: loss=1.304, acc=54%\n",
      " 40) pretrained: loss=0.749, acc=68%\n",
      " 50) pretrained: loss=0.673, acc=66%\n",
      " 60) pretrained: loss=0.749, acc=72%\n",
      " 70) pretrained: loss=1.064, acc=54%\n",
      " 80) pretrained: loss=0.825, acc=66%\n",
      " 90) pretrained: loss=0.893, acc=64%\n",
      "100) pretrained: loss=1.155, acc=60%\n",
      "110) pretrained: loss=1.541, acc=46%\n",
      "120) pretrained: loss=1.221, acc=54%\n",
      "130) pretrained: loss=1.181, acc=56%\n",
      "140) pretrained: loss=1.511, acc=62%\n",
      "150) pretrained: loss=0.685, acc=70%\n",
      "160) pretrained: loss=1.848, acc=38%\n",
      "170) pretrained: loss=1.563, acc=56%\n",
      "180) pretrained: loss=1.017, acc=56%\n",
      "190) pretrained: loss=1.337, acc=56%\n",
      "199) pretrained: loss=0.957, acc=70%\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "niter = 200  # number of iterations to train\n",
    "\n",
    "# Reset style_solver as before.\n",
    "aest_solver_filename = aestheticNet.solver(aestheticNet.aest_net(train=True))\n",
    "aest_solver = caffe.get_solver(aest_solver_filename)\n",
    "aest_solver.net.copy_from(weights)\n",
    "\n",
    "\n",
    "print ('Running solvers for %d iterations...' % niter)\n",
    "solvers = [('pretrained', aest_solver)]\n",
    "loss, acc, weights = aestheticNet.run_solvers(niter, solvers)\n",
    "print ('Done.')\n",
    "\n",
    "train_loss = loss['pretrained']\n",
    "train_acc = acc['pretrained']\n",
    "aest_weights = weights['pretrained']\n",
    "\n",
    "# Delete solvers to save memory.\n",
    "del aest_solver, solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, trained from ImageNet initialization: 62.6%\n"
     ]
    }
   ],
   "source": [
    "test_net, accuracy = aestheticNet.eval_aest_net(aest_weights)\n",
    "print ('Accuracy, trained from ImageNet initialization: %3.1f%%' % (100*accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.39917552,  0.39917469],\n",
       "       [-4.64230108,  4.64230108],\n",
       "       [-1.30723464,  1.30723369],\n",
       "       [-2.5332756 ,  2.53327417],\n",
       "       [-1.82000899,  1.82000852],\n",
       "       [-1.94184339,  1.94184279],\n",
       "       [-3.18653512,  3.18653321],\n",
       "       [-3.02499008,  3.02498913],\n",
       "       [-3.28335667,  3.28335619],\n",
       "       [-4.09701347,  4.09701347],\n",
       "       [-2.08524251,  2.08524251],\n",
       "       [-1.13544047,  1.13543928],\n",
       "       [ 0.10276354, -0.10276448],\n",
       "       [-1.94203353,  1.94203234],\n",
       "       [-0.64010638,  0.64010543],\n",
       "       [-1.92276156,  1.92276073],\n",
       "       [-3.05125403,  3.05125213],\n",
       "       [-2.0735569 ,  2.07355571],\n",
       "       [-0.92093992,  0.9209401 ],\n",
       "       [-0.20936368,  0.20936294],\n",
       "       [-0.93388695,  0.93388683],\n",
       "       [-1.10290885,  1.10290718],\n",
       "       [-2.44362593,  2.44362497],\n",
       "       [-0.07105487,  0.07105384],\n",
       "       [-2.25691867,  2.25691772],\n",
       "       [-1.06756175,  1.06756115],\n",
       "       [-0.85353696,  0.8535375 ],\n",
       "       [-1.91471171,  1.91471052],\n",
       "       [-2.78103471,  2.78103399],\n",
       "       [-1.79195738,  1.79195595],\n",
       "       [-0.64182335,  0.64182287],\n",
       "       [-5.79403734,  5.79403496],\n",
       "       [-1.00976193,  1.00976121],\n",
       "       [ 0.48045242, -0.48045376],\n",
       "       [-1.94914293,  1.94914198],\n",
       "       [ 0.69094431, -0.69094497],\n",
       "       [-0.02330092,  0.02330044],\n",
       "       [-3.55201149,  3.55201006],\n",
       "       [-2.01980972,  2.01980805],\n",
       "       [-0.71519822,  0.71519762],\n",
       "       [-0.13032228,  0.13032131],\n",
       "       [ 0.98332894, -0.98332977],\n",
       "       [-1.90688729,  1.90688586],\n",
       "       [-2.04318547,  2.04318428],\n",
       "       [-1.0105691 ,  1.01056957],\n",
       "       [-2.38745785,  2.38745666],\n",
       "       [-1.24291873,  1.24291837],\n",
       "       [ 0.34654179, -0.34654227],\n",
       "       [ 0.02781788, -0.02781921],\n",
       "       [-1.64606953,  1.64606977]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_net.blobs['fc8_aesthetic'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
