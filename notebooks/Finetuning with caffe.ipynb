{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set up Python environment: numpy for numerical routines, and matplotlib for plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# display plots in this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# for store the results\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "# for include pycode\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0,'../pycode')\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The caffe module needs to be on the Python path;\n",
    "#  we'll add it here explicitly.\n",
    "caffe_root = '/opt/caffe/'  # this file should be run from {caffe_root}/examples (otherwise change this line)\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "\n",
    "import caffe\n",
    "from caffe import layers as L\n",
    "# If you get \"No module named _caffe\", either you have not built pycaffe or you have the wrong path.\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "import aestheticNet\n",
    "from preprocess import utilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utilsData\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Generacion de train y test\n",
    "Primero creamos dos txt con la informacion del fichero y de su clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = pickle.load(gzip.open('../packages/AVA_info.pklz','rb',2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data.loc[:,'id'] = data['id'].apply(str)\n",
    "classes = np.array(data.sort_values(['id']).loc[:,'Class'])\n",
    "ids = np.array(data.sort_values(['id']).loc[:,'id'])\n",
    "aux_list =  np.array(['/home/frubio/AVA/AVADataset/{:}.jpg'.format(i) for i in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1000)\n",
    "random_idx = np.random.randint(3, size=len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_files = aux_list[random_idx <= 1]\n",
    "train_classes = classes[random_idx <= 1]\n",
    "# Class balanced\n",
    "new_indexes = utilities.balance_class(train_classes)\n",
    "train_classes = train_classes[new_indexes]\n",
    "train_files = train_files[new_indexes]\n",
    "\n",
    "test_files = aux_list[random_idx == 2]\n",
    "test_classes = classes[random_idx == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(list(zip(train_files,train_classes)))\n",
    "df_train.columns = ['image_filename', 'label']\n",
    "df_train.to_csv('../../AVA/train_partition_finetuning.txt', sep=' ', header=None, index=None)\n",
    "\n",
    "df_test = pd.DataFrame(list(zip(test_files,test_classes)))\n",
    "df_test.columns = ['image_filename', 'label']\n",
    "df_test.to_csv('../../AVA/test_partition_finetuning.txt', sep=' ', header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Aqui comienza la chicha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "caffe.set_device(0)  # if we have multiple GPUs, pick the first one\n",
    "#caffe.set_mode_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weights = caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "niter = 100000  # number of iterations to train\n",
    "\n",
    "# Reset style_solver as before.\n",
    "style_solver_filename = aestheticNet.solver(aestheticNet.aest_net(train=True,caffe_aes=True))\n",
    "style_solver = caffe.get_solver(style_solver_filename)\n",
    "style_solver.net.copy_from(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print ('Running solvers for %d iterations...' % niter)\n",
    "solvers = [('pretrained', style_solver)]\n",
    "loss, acc, weights = aestheticNet.run_solvers(niter, solvers)\n",
    "print ('Done.')\n",
    "\n",
    "train_loss = loss['pretrained']\n",
    "train_acc = acc['pretrained']\n",
    "style_weights = weights['pretrained']\n",
    "\n",
    "# Delete solvers to save memory.\n",
    "del style_solver, solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "os.rename(weights['pretrained'], \"/home/frubio/AVA/aesthetic_finetuning.caffemodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_def = aestheticNet.aest_net(train=False,caffe_aes=True)\n",
    "model_weights = \"/home/frubio/AVA/aesthetic_finetuning.caffemodel\"\n",
    "\n",
    "net = caffe.Net(model_def,      # defines the structure of the model\n",
    "                model_weights,  # contains the trained weights\n",
    "                caffe.TEST)     # use test mode (e.g., don't perform dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the mean ImageNet image (as distributed with Caffe) for subtraction\n",
    "mu = np.load(caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy')\n",
    "mu = mu.mean(1).mean(1)  # average over pixels to obtain the mean (BGR) pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create transformer for the input called 'data'\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "transformer.set_transpose('data', (2,0,1))  # move image channels to outermost dimension\n",
    "transformer.set_mean('data', mu)            # subtract the dataset-mean value in each channel\n",
    "transformer.set_raw_scale('data', 255)      # rescale from [0, 1] to [0, 255]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # swap channels from RGB to BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_images = test_files.shape[0]\n",
    "output_prob = np.zeros(num_images)\n",
    "batch_size = net.blobs['data'].data.shape[0]\n",
    "\n",
    "num_forwards = np.ceil(num_images/batch_size).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (50) into shape (5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-da64a13d7eb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0moutput_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimages_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mimages_step\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimages_to_process\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'probs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (50) into shape (5)"
     ]
    }
   ],
   "source": [
    "for i in range(0,num_forwards):\n",
    "    images_step = i*batch_size\n",
    "    \n",
    "    if (i == num_forwards - 1):\n",
    "        images_to_process = num_images - images_step\n",
    "    else:\n",
    "        images_to_process = batch_size\n",
    "            \n",
    "    for j in range(0,images_to_process):\n",
    "        # these lines is for those images that have four dimensions\n",
    "        checked_image = caffe.io.load_image(test_files[j+images_step])\n",
    "        if (len(checked_image.shape)==4):\n",
    "            checked_image = checked_image[0]\n",
    "                \n",
    "        net.blobs['data'].data[j] = transformer.preprocess('data',checked_image)\n",
    "        \n",
    "    net.forward()\n",
    "    output_prob[images_step:images_step+images_to_process] = net.blobs['probs'].data[0:images_to_process,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "results['balanced'] = utilsData.balanced_accuracy(test_classes, output_prob)\n",
    "results['AUC'] = roc_auc_score(test_classes, output_prob)\n",
    "results['accuracy'] = accuracy_score(test_classes, (output_prob >= 0.5).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(results, gzip.open( \"../results/CNN_finetuning_CaffeNet.pklz\", \"wb\" ), 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
